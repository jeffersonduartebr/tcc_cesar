{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "import swifter\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('dados/TJRN_17463_2017-01-01.csv'):\n",
    "    df_tjrn = pd.read_csv('dados/TJRN_17463_2017-01-01.csv', header='infer', sep=';', compression='zip')\n",
    "else:\n",
    "    df_tjrn = pd.read_csv(glob.glob(\"dados/TJRN_17*.csv\")[0], header='infer', sep=';', compression='zip')\n",
    "    print(f'Carregando o dataset referente ao {glob.glob(\"dados/TJRN_17*.csv\")[0]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tjrn.drop_duplicates(inplace=True)\n",
    "if 'sort' in df_tjrn.columns:\n",
    "    df_tjrn.drop(columns=['sort'], inplace=True)\n",
    "if 'classe' in df_tjrn.columns:\n",
    "    df_tjrn.drop(columns=['classe'], inplace=True)    \n",
    "if 'grau' in df_tjrn.columns:\n",
    "    df_tjrn.drop(columns=['grau'], inplace=True)\n",
    "if 'orgao_julgador' in df_tjrn.columns:\n",
    "    df_tjrn.drop(columns=['orgao_julgador'], inplace=True)\n",
    "    \n",
    "if df_tjrn['assuntos'].isna().sum() > (0.8 * len(df_tjrn['assuntos'])):\n",
    "    df_tjrn.drop(columns=['assuntos'], inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tjrn.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_tjrn['data_ajuizamento'] = pd.to_datetime(df_tjrn['data_ajuizamento'], utc=True)\n",
    "print(df_tjrn.info())\n",
    "df_tjrn['data_ajuizamento'] = df_tjrn['data_ajuizamento'].dt.strftime('%Y-%m-%d')\n",
    "df_tjrn['ultima_atualizacao'] = pd.to_datetime(df_tjrn['ultima_atualizacao'], format='mixed').dt.strftime('%Y-%m-%d')\n",
    "print(df_tjrn.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movimentacoes = list(df_tjrn.movimentos.values)\n",
    "print(len(movimentacoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movimentacoes[0])\n",
    "print(df_tjrn['movimentos'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" lista_movimentacoes_completa = []\n",
    "lista_codigos = list()\n",
    "lista_nomes = list()\n",
    "lista_data = list()\n",
    "i = 0\n",
    "\n",
    "for movimento in movimentacoes:\n",
    "    if '272' in movimento.split():\n",
    "        print(movimento)\n",
    "        continue \n",
    "        #print(len(list(movimento.split(',')))/4)\n",
    "    else:\n",
    "        if len(list(movimento.split(','))) % 4 == 0:\n",
    "            for elemento in range(0,int(len(list(movimento.split(',')))/4),4):\n",
    "                if elemento != None:\n",
    "                    codigo = movimento.split(',')[elemento].replace('[','').replace(' ', '')\n",
    "                    nome_movimentacao = movimento.split(',')[elemento+1].replace('[','').replace(' ', '')\n",
    "                    data_movimentacao = movimento.split(',')[elemento+2].replace('[','').replace('Timestamp(','').split(' ')[1].replace(' ', '').replace('\\'', '')\n",
    "                    lista_temp = list()\n",
    "                    lista_temp.append([codigo, nome_movimentacao, data_movimentacao])\n",
    "                    #lista_temp.append(nome_movimentacao)\n",
    "                    #lista_temp.append(data_movimentacao)\n",
    "                    #lista_movimentacoes_completa.append([])\n",
    "                    lista_movimentacoes_completa.append(lista_temp)\n",
    "                else:\n",
    "                    lista_temp = [-1, -1, -1]\n",
    "                    #lista_movimentacoes_completa.append([])\n",
    "                    lista_movimentacoes_completa.append(lista_temp)\n",
    "            i = i + 1 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_movimentacoes_completa = []\n",
    "lista_codigos = list()\n",
    "lista_nomes = list()\n",
    "lista_data = list()\n",
    "i = 0\n",
    "\n",
    "for movimento in movimentacoes:\n",
    "    if '272' in movimento.split():\n",
    "        print(movimento)\n",
    "        #continue \n",
    "        #print(len(list(movimento.split(',')))/4)\n",
    "    else:\n",
    "        if len(list(movimento.split(','))) % 4 == 0:\n",
    "            lista_temp = list()\n",
    "            for elemento in range(0,int(len(list(movimento.split(',')))/4),4):\n",
    "                codigo = movimento.split(',')[elemento].replace('[','').replace(' ', '')\n",
    "                nome_movimentacao = movimento.split(',')[elemento+1].replace('[','').replace(' ', '')\n",
    "                data_movimentacao = movimento.split(',')[elemento+2].replace('[','').replace('Timestamp(','').split(' ')[1].replace(' ', '').replace('\\'', '')\n",
    "                lista_temp.append([codigo, nome_movimentacao, data_movimentacao])\n",
    "        else:\n",
    "            lista_temp.append([-1,-1,-1])\n",
    "    lista_movimentacoes_completa.append(lista_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lista_movimentacoes_completa))\n",
    "#lista_movimentacoes_completa = list(filter(None, lista_movimentacoes_completa))\n",
    "print(len(movimentacoes), '\\t', movimentacoes[0])\n",
    "print(len(lista_movimentacoes_completa), '\\t', lista_movimentacoes_completa[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(lista_movimentacoes_completa), len(lista_movimentacoes_completa))\n",
    "print(type(lista_movimentacoes_completa[0]), len(lista_movimentacoes_completa[2]))\n",
    "print(lista_movimentacoes_completa[5200])\n",
    "print(lista_movimentacoes_completa[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lista_movimentacoes_completa[0])\n",
    "print(df_tjrn['movimentos'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movimentacoes_gabinete = pd.read_csv('dados/movimentos_gabinete.csv', sep=';', header='infer')\n",
    "movimentacoes_gabinete['codigo'] = movimentacoes_gabinete['vazio.1']\n",
    "movimentacoes_gabinete.drop(columns=['complemento','vazio', 'vazio.2', 'vazio.1'], inplace=True)\n",
    "lista_movimentacoes_sentenca = movimentacoes_gabinete[movimentacoes_gabinete['nome'] == 'Julgamento']['codigo'].to_list()\n",
    "print(movimentacoes_gabinete.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movimentacoes_gabinete[movimentacoes_gabinete['nome'] == 'Julgamento'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movimentacoes_secretaria = pd.read_csv('dados/movimentos_secretaria.csv', sep=';', header='infer')\n",
    "print(movimentacoes_secretaria.head(5))\n",
    "movimentacoes_secretaria.drop(columns=['Unnamed: 3','complemento'], inplace=True)\n",
    "lista_movimentacoes_secretaria = movimentacoes_secretaria['codigo'].to_list()\n",
    "print(movimentacoes_secretaria.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_data_sentenca(movimentacoes):\n",
    "    processos_sentenciados = 0\n",
    "    processos_nao_sentenciados = 0    \n",
    "    lista_data_sentenca = list()\n",
    "    for i in range(0,(len(movimentacoes)),1):\n",
    "        processado = False\n",
    "        if len(movimentacoes[i]) > 3:\n",
    "            for j in range(0,(len(movimentacoes[i])-1),3):\n",
    "                #print(movimentacoes[i][j][0])\n",
    "                if processado:\n",
    "                   break \n",
    "                if int(movimentacoes[i][j][0]) in lista_movimentacoes_sentenca:\n",
    "                    data = pd.to_datetime(movimentacoes[i][j][2])\n",
    "                    data = data.date().strftime(\"%Y-%m-%d\")\n",
    "                    lista_data_sentenca.append(data)\n",
    "                    processos_sentenciados = processos_sentenciados + 1\n",
    "                    processado = True\n",
    "                    #print(f'Processando: {i}: Sentença encontrada')\n",
    "            if not processado:\n",
    "                lista_data_sentenca.append('-1')\n",
    "                processado = True\n",
    "                processos_nao_sentenciados = processos_nao_sentenciados + 1         \n",
    "   \n",
    "                #print(f'data adicionada: {data}')    \n",
    "        else:\n",
    "            #print(movimentacoes[i])\n",
    "            lista_data_sentenca.append('-1')\n",
    "            processos_nao_sentenciados = processos_nao_sentenciados + 1\n",
    "            #print(f'data adicionada: {data_default_nao_sentenciados}')\n",
    "            #print(f'Processando: {i}: SEM movimentação do gabinete')\n",
    "    print(f'processos sentenciados: {processos_sentenciados}\\tprocessos não sentenciados: {processos_nao_sentenciados}')\n",
    "    return lista_data_sentenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(calcular_data_sentenca(lista_movimentacoes_completa))\n",
    "print(len(lista_movimentacoes_completa), len(calcular_data_sentenca(lista_movimentacoes_completa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciona ok.\n",
    "def calcular_tempo_entre_movimentacoes(movimentacoes, mov_inicial, mov_final):\n",
    "    lista_duracao = list()\n",
    "    for i in range(0,(len(movimentacoes)),1):\n",
    "        #if i < 3:\n",
    "            #print(movimentacoes[i])\n",
    "        if ((len(movimentacoes[i]) > 3) and (len(movimentacoes[i]) >= mov_final)):\n",
    "            try:\n",
    "                duracao = abs(pd.to_datetime(movimentacoes[i][mov_final][2]) - pd.to_datetime(movimentacoes[i][mov_inicial][2]))/np.timedelta64(1, 'D')\n",
    "                lista_duracao.append(int(duracao))\n",
    "            except:\n",
    "                lista_duracao.append(int(-1))          \n",
    "\n",
    "        else: \n",
    "            lista_duracao.append(int(-1))\n",
    "            \n",
    "    return lista_duracao        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tjrn['data_sentenca'] = calcular_data_sentenca(lista_movimentacoes_completa)\n",
    "df_tjrn['movimentos'] = lista_movimentacoes_completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estatisticas_movimentacoes_processo(movimentacoes):\n",
    "    min = np.inf\n",
    "    max = 0\n",
    "    media = 0.0\n",
    "    lista_mov_processos = list()\n",
    "    for movimento in movimentacoes:\n",
    "        lista_mov_processos.append(len(movimento)/3)\n",
    "        if len(movimento)/3 > max:\n",
    "            max = len(movimento)/3\n",
    "        elif len(movimento)/3 < min:\n",
    "            min = len(movimento)/3\n",
    "        media += len(movimento)/3\n",
    "    media = media / len(movimentacoes)\n",
    "    return media, lista_mov_processos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tjrn['tempo_entre_1e2_mov'] = calcular_tempo_entre_movimentacoes(df_tjrn['movimentos'].to_list(),0,1)\n",
    "df_tjrn['tempo_entre_2e3_mov'] = calcular_tempo_entre_movimentacoes(df_tjrn['movimentos'].to_list(),1,2)\n",
    "df_tjrn['tempo_entre_3e4_mov'] = calcular_tempo_entre_movimentacoes(df_tjrn['movimentos'].to_list(),2,3)\n",
    "#df_tjrn['tempo_entre_4e5_mov'] = calcular_tempo_entre_movimentacoes(df_tjrn['movimentos'].to_list(),4,5)\n",
    "\n",
    "df_tjrn['mais60d'] = (df_tjrn['tempo_entre_1e2_mov'] > 60) | (df_tjrn['tempo_entre_2e3_mov'] > 60) | (df_tjrn['tempo_entre_3e4_mov'] > 60) #| (df_tjrn['tempo_entre_4e5_mov'] > 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tjrn['mais60d'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentenciados = df_tjrn[df_tjrn['data_sentenca'] != '-1']\n",
    "df_sentenciados['tempo_ate_sentenca'] = abs(pd.to_datetime(df_sentenciados['data_sentenca']) - pd.to_datetime(df_sentenciados['data_ajuizamento']))/np.timedelta64(1, 'D')\n",
    "df_nao_sentenciados = df_tjrn[df_tjrn['data_sentenca'] == '-1']\n",
    "df_nao_sentenciados['tempo_ate_sentenca'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sentenciados.shape)\n",
    "print(df_nao_sentenciados.shape)\n",
    "print(df_tjrn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tjrn = pd.concat([df_sentenciados, df_nao_sentenciados])\n",
    "print(df_tjrn.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estatísticas iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_sentenciados.shape[0], df_nao_sentenciados.shape[0])\n",
    "percentual_sentenciados = (int(df_sentenciados.shape[0])/int(df_nao_sentenciados.shape[0]) * 100)\n",
    "percentual_sentenciados = float(\"{:.4f}\".format(percentual_sentenciados))\n",
    "print(f'Percentual da base de casos sentenciados: {percentual_sentenciados}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentenciados.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentenciados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_sentenciados, x='data_ajuizamento', marginal='rug', title='Distribuição dos processos já sentenciados pela data de ajuizamento')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_nao_sentenciados, x='data_ajuizamento', marginal='rug', title='Distribuição dos processos ainda não sentenciados pela data de ajuizamento')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_sentenciados, x='tempo_ate_sentenca', marginal='rug', title='Distribuição do tempo até a sentença')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media, lista_mov_processos = estatisticas_movimentacoes_processo(df_sentenciados['movimentos'].to_list())\n",
    "print(f'Média de movimentações por processo: {media}')\n",
    "fig = px.histogram(lista_mov_processos, marginal='rug', title='Distribuição do número de movimentações por processo',\n",
    "                   nbins=math.ceil((media *2)), labels={'x':'Movimentações', 'y':'Ocorrências'}).update_layout(\n",
    "    yaxis_title=\"Ocorrências\", xaxis_title=\"Movimentações\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes com ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tjrn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df_sentenciados.drop(columns=['movimentos', 'numero_processo', 'data_ajuizamento', 'ultima_atualizacao', 'codigo', 'data_sentenca' ])\n",
    "df_ml = pd.get_dummies(df_ml, columns=['assuntos'], drop_first=True)\n",
    "df_x = df_ml.drop(columns=['tempo_ate_sentenca', 'mais60d', 'tempo_entre_3e4_mov'])\n",
    "#print(df_ml.head(1))\n",
    "print(df_ml.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "metricas = ['accuracy', 'f1', 'precision', 'recall']\n",
    "rfc = RandomForestClassifier(random_state=19, n_jobs=-1)\n",
    "adc = AdaBoostClassifier(random_state=19,algorithm=\"SAMME\", n_estimators=200)\n",
    "mlp = MLPClassifier(random_state=19)\n",
    "dtc = DecisionTreeClassifier(random_state=19)\n",
    "\n",
    "scores_rfc = cross_validate(rfc, df_x,\n",
    "                             df_ml['mais60d'], cv=10, scoring=metricas)\n",
    "scores_adc = cross_validate(adc, df_x,\n",
    "                             df_ml['mais60d'], cv=10, scoring=metricas)\n",
    "scores_mlp = cross_validate(mlp, df_x,\n",
    "                             df_ml['mais60d'], cv=10, scoring=metricas)\n",
    "scores_dtc = cross_validate(dtc, df_x,\n",
    "                             df_ml['mais60d'], cv=10, scoring=metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaves = scores_dtc.keys()\n",
    "print(f'Usando as colunas {df_x.columns} chegou-se ao seguinte resultado\\n\\n')\n",
    "print(f'Métrica \\tRandomForest \\tAdaBoost \\tMLP \\tDecisionTree')\n",
    "for chave in chaves:\n",
    "    print(f'{chave}:\\t {scores_rfc[chave].mean():.3f} \\t\\t{scores_adc[chave].mean():.3f} \\t\\t{scores_mlp[chave].mean():.3f} \\t\\t{scores_dtc[chave].mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo tentando prever se vai atrasar ou não"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_ml['mais60d'],test_size=0.20, random_state=19)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=10).fit(X_train, y_train)\n",
    "print(clf.score(X_test,y_test))\n",
    "r = export_text(clf, feature_names=df_x.columns)\n",
    "\n",
    "print(r)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão para o tempo até a sentença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, \n",
    "                                                    df_ml['tempo_ate_sentenca'], test_size=0.20, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=250)\n",
    "model.fit(X_train, y_train)\n",
    "rf_y_pred = model.predict(X_test)\n",
    "\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_rmse = mean_squared_error(y_test, rf_y_pred, squared=False)\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "print(f'AdaBoost Regressor')\n",
    "regr = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "ada_y_pred = regr.predict(X_test)\n",
    "\n",
    "ada_r2 = r2_score(y_test, ada_y_pred)\n",
    "ada_mae = mean_absolute_error(y_test, ada_y_pred)\n",
    "ada_rmse = mean_squared_error(y_test, ada_y_pred, squared=False)\n",
    "ada_mse = mean_squared_error(y_test, ada_y_pred)\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "print(f'MLP Regressor')\n",
    "\n",
    "regr_mlp = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
    "mlp_y_pred = regr_mlp.predict(X_test)\n",
    "\n",
    "mlp_r2 = r2_score(y_test, mlp_y_pred)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_y_pred)\n",
    "mlp_rmse = mean_squared_error(y_test, mlp_y_pred, squared=False)\n",
    "mlp_mse = mean_squared_error(y_test, mlp_y_pred)\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "print(f'DT Regressor')\n",
    "regressor = DecisionTreeRegressor(random_state=0).fit(X_train, y_train)\n",
    "dt_y_pred = regr_mlp.predict(X_test)\n",
    "\n",
    "dt_r2 = r2_score(y_test, dt_y_pred)\n",
    "dt_mae = mean_absolute_error(y_test, dt_y_pred)\n",
    "dt_rmse = mean_squared_error(y_test, dt_y_pred, squared=False)\n",
    "dt_mse = mean_squared_error(y_test, dt_y_pred)\n",
    "\n",
    "print(f'Metric\\t\\t\\t\\t RF\\t AdaBoost\\t MLP\\t\\t DT')\n",
    "print(f\"Mean Squared Error:\\t\\t {rf_r2:.3f}\\t {ada_r2:.3f}\\t\\t {mlp_r2:.3f}\\t\\t {dt_r2:.3f}\")\n",
    "print(f\"R-squared (R²):\\t\\t\\t {rf_mae:.3f}\\t {ada_mae:.3f}\\t {mlp_mae:.3f}\\t\\t {dt_mae:.3f}\")\n",
    "print(f\"Mean Absolute Error (MAE):\\t {rf_mae:.3f}\\t {ada_rmse:.3f}\\t {mlp_rmse:.3f}\\t {dt_rmse:.3f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):\\t {rf_rmse:.3f} {ada_mse:.3f}\\t {mlp_mse:.3f}\\t {dt_mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=3, random_state=19)\n",
    "rfc = RandomForestRegressor()\n",
    "\n",
    "param_grid = [{'n_estimators': [100, 300, 500],\n",
    "               'min_samples_split': [2, 5, 25],\n",
    "               'min_samples_leaf': [3, 4, 5, 20],\n",
    "               'max_depth': [5, 35, 50]}]\n",
    "\n",
    "clf = GridSearchCV(rfc, param_grid = param_grid, n_jobs=-1, scoring='roc_auc', verbose=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "best_model = clf.best_estimator_ \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" results_df = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
    "results_df = results_df.set_index(\n",
    "    results_df[\"params\"].apply(lambda x: \"_\".join(str(val) for val in x.values()))\n",
    ").rename_axis(\"kernel\")\n",
    "#print(results_df.columns)\n",
    "results_df = results_df[[\"params\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]\n",
    "\n",
    "print(results_df.head(3)) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
