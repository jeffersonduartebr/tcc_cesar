{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wwDWkrHvGD5N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import datetime\n",
        "import concurrent.futures\n",
        "import swifter\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zgfVV605bUpu"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)  # or 1000\n",
        "pd.set_option('display.max_rows', None)  # or 1000\n",
        "pd.set_option('display.max_colwidth', None)  # or 199"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def converte_data(data_str):\n",
        "    return pd.to_datetime(data_str).tz_convert('America/Sao_Paulo')\n",
        "\n",
        "\n",
        "def gera_lista_assuntos(assuntos_do_df):\n",
        "    lst_assuntos=[]\n",
        "    for assunto in assuntos_do_df:\n",
        "        try:\n",
        "            lst_assuntos.append(assunto.get('nome'))\n",
        "        except:\n",
        "            lst_assuntos.append('')\n",
        "\n",
        "    return lst_assuntos\n",
        "\n",
        "\n",
        "def gera_lista_movimentos(movimentos):\n",
        "    lst_movimentos_final =[]\n",
        "    for movimento in movimentos:\n",
        "        codigo = movimento.get('codigo')\n",
        "        nome = movimento.get('nome')\n",
        "        data_hora = movimento.get('dataHora')\n",
        "        if data_hora:\n",
        "            data_hora = converte_data(data_hora)\n",
        "        lst_movimentos_final.append([ codigo, nome, data_hora])\n",
        "    return lst_movimentos_final\n",
        "\n",
        "def process_movimento(movimento):\n",
        "    codigo = movimento.get('codigo')\n",
        "    nome = movimento.get('nome')\n",
        "    data_hora = movimento.get('dataHora')\n",
        "    if data_hora:\n",
        "        data_hora = converte_data(data_hora)\n",
        "    return [codigo, nome, data_hora]\n",
        "\n",
        "def gera_lista_movimentos_multithread(movimentos):\n",
        "    lst_movimentos_final = []\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        results = list(executor.map(process_movimento, movimentos))\n",
        "        lst_movimentos_final.extend(results)\n",
        "    return lst_movimentos_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fCRLqGiKGD5Q"
      },
      "outputs": [],
      "source": [
        "def lista_para_dataframe(dados_dict):\n",
        "  processos = []\n",
        "  for processo in dados_dict['hits']['hits']:\n",
        "    numero_processo = processo['_source']['numeroProcesso']\n",
        "    grau = processo['_source']['grau']\n",
        "    classe = processo['_source']['classe']['codigo']\n",
        "    try:\n",
        "      assuntos = processo['_source']['assuntos'] # Pode ter mais de um\n",
        "    except:\n",
        "      assuntos = []\n",
        "    data_ajuizamento = processo['_source']['dataAjuizamento']\n",
        "    ultima_atualizacao = processo['_source']['dataHoraUltimaAtualizacao']\n",
        "    #formato = processo['_source']['formato']['nome']\n",
        "    codigo = processo['_source']['orgaoJulgador']['codigo']\n",
        "    orgao_julgador = processo['_source']['orgaoJulgador']['nome']\n",
        "    municipio = processo['_source']['orgaoJulgador']['codigoMunicipioIBGE']\n",
        "    sort = processo['sort'][0]\n",
        "    try:\n",
        "      movimentos = processo['_source']['movimentos']\n",
        "    except:\n",
        "      movimentos = []\n",
        "\n",
        "    processos.append([numero_processo, classe, data_ajuizamento, ultima_atualizacao, \\\n",
        "                      codigo, orgao_julgador, municipio, grau, assuntos, movimentos, sort])\n",
        "\n",
        "  df = pd.DataFrame(processos, columns=['numero_processo', 'codigo_classe', 'data_ajuizamento', 'ultima_atualizacao', \\\n",
        "                        'codigo', 'orgao_julgador', 'municipio', 'grau', 'assuntos', 'movimentos', 'sort'])\n",
        "  df['movimentos'] = df['movimentos'].swifter.apply(gera_lista_movimentos_multithread)\n",
        "  df['assuntos'] = df['assuntos'].swifter.apply(gera_lista_assuntos)\n",
        "  #df['movimentos'] = df['movimentos'].swifter.apply(gera_lista_movimentos_multithread)\n",
        "  df['data_ajuizamento'] = df['data_ajuizamento'].swifter.apply(converte_data)\n",
        "  df['ultima_atualizacao'] = df['ultima_atualizacao'].swifter.apply(converte_data)\n",
        "  try:\n",
        "    df['movimentos']= df['movimentos'].swifter.apply(lambda x: sorted(x, key=lambda tup: tup[2], reverse=False))\n",
        "  except:\n",
        "    pass\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L6SQFgbGD5O",
        "outputId": "b5955baf-6132-4b09-f181-3a68bc5ca34c"
      },
      "outputs": [],
      "source": [
        "def criar_dataset(tribunal, data, tamanho_consulta, grau='JE'):\n",
        "  match tribunal:\n",
        "    case 'TRF1':\n",
        "      tribunal = 'TRF1'\n",
        "      url = \"https://api-publica.datajud.cnj.jus.br/api_publica_trf1/_search\"\n",
        "    case 'TRF2':\n",
        "      tribunal = 'TRF2'\n",
        "      url = \"https://api-publica.datajud.cnj.jus.br/api_publica_trf2/_search\"    \n",
        "    case 'TRF3':\n",
        "      tribunal = 'TRF3'\n",
        "      url = \"https://api-publica.datajud.cnj.jus.br/api_publica_trf3/_search\"      \n",
        "    case 'TRF4':\n",
        "      tribunal = 'TRF4'\n",
        "      url = \"https://api-publica.datajud.cnj.jus.br/api_publica_trf4/_search\"  \n",
        "    case _:\n",
        "      tribunal = 'TRF4'\n",
        "      url = \"https://api-publica.datajud.cnj.jus.br/api_publica_trf4/_search\"          \n",
        "  df_tjrn = pd.DataFrame()\n",
        "\n",
        "  api_key = \"APIKey cDZHYzlZa0JadVREZDJCendQbXY6SkJlTzNjLV9TRENyQk1RdnFKZGRQdw==\" # Chave pública\n",
        "  size = tamanho_consulta\n",
        "  data = data\n",
        "  grau = grau\n",
        "\n",
        "  payload = json.dumps(\n",
        "  {\n",
        "  \"size\": tamanho_consulta,\n",
        "  \"query\": {\n",
        "      \"bool\": {\n",
        "        \"must\": [\n",
        "            {\"match\": {\"tribunal\": tribunal}},\n",
        "            {\"match\": {\"grau\": grau}},            \n",
        "            {\"range\": {\"dataAjuizamento\": {\"gte\": data }}}\n",
        "        ]\n",
        "      }\n",
        "  },\n",
        "    \"sort\": [{\"@timestamp\": {\"order\": \"asc\"}}]\n",
        "  })\n",
        "\n",
        "  headers = {\n",
        "    'Authorization': api_key,\n",
        "    'Content-Type': 'application/json'\n",
        "  }\n",
        "\n",
        "  response = requests.request(\"POST\", url, headers=headers, data=payload)  # <Response [200]>\n",
        "  dados_dict = response.json() # <class 'dict'>\n",
        "  if len(dados_dict['hits']['hits']) < 5:\n",
        "    print(f'Parece que você digitou um código de Serventia errado. Confira novamente.')\n",
        "  df_tjrn = lista_para_dataframe(dados_dict)\n",
        "  numero_processos = size\n",
        "\n",
        "  while numero_processos == size:\n",
        "    numero_processos = len(dados_dict['hits']['hits'])\n",
        "    tamanho_dicionario_retornado = len(dados_dict['hits']['hits'])-1\n",
        "    if tamanho_dicionario_retornado < 1:\n",
        "      print(f'Tamanho do dicionário da página anterior: {tamanho_dicionario_retornado}')\n",
        "      continue\n",
        "    ultima_posicao_dicionario = dados_dict['hits']['hits'][(len(dados_dict['hits']['hits'])-1)]['sort'][0]\n",
        "    #print(f'Partindo da posição: {ultima_posicao_dicionario}')\n",
        "    payload = json.dumps(\n",
        "    {\n",
        "    \"size\": tamanho_consulta,\n",
        "    \"query\": {\n",
        "        \"bool\": {\n",
        "          \"must\": [\n",
        "            {\"match\": {\"tribunal\": tribunal}},\n",
        "            {\"match\": {\"grau\": grau}},               \n",
        "            {\"range\": {\"dataAjuizamento\": {\"gte\": data}}}\n",
        "            \n",
        "          ]\n",
        "        }\n",
        "    },\n",
        "      \"search_after\": [ ultima_posicao_dicionario ],\n",
        "      \"sort\": [{\"@timestamp\": {\"order\": \"asc\"}}]\n",
        "    })\n",
        "\n",
        "    headers = {\n",
        "      'Authorization': api_key,\n",
        "      'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    response = requests.request(\"POST\", url, headers=headers, data=payload)  # <Response [200]>\n",
        "    dados_dict = response.json() # <class 'dict'>\n",
        "    numero_processos = len(dados_dict['hits']['hits'])\n",
        "    ultima_posicao_dicionario = dados_dict['hits']['hits'][(len(dados_dict['hits']['hits'])-1)]['sort']\n",
        "    df_tjrn = pd.concat([df_tjrn, lista_para_dataframe(dados_dict)])\n",
        "    df_tjrn = df_tjrn[df_tjrn['grau'] == grau]\n",
        "    tamanho_dataset = len(df_tjrn.index)\n",
        "    ultima_data_ajuizamento = dados_dict['hits']['hits'][len(dados_dict['hits']['hits'])-1]['_source']['dataAjuizamento']\n",
        "    print(f'{datetime.datetime.now()}\\t Número de processos: {tamanho_dataset} \\t Data do último processo adicionado: {ultima_data_ajuizamento}' )\n",
        "    #if tamanho_dataset > 2000000:\n",
        "    #  break\n",
        "\n",
        "  try:\n",
        "    print(f'Número de processos incorporados: {tamanho_dataset}')\n",
        "  except:\n",
        "    print(f'Última página do dicionário veio vazia: {tribunal}')\n",
        "  #print(df_tjrn.head(1))\n",
        "  return df_tjrn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def salvar_dataset(df, orgao, grau , data):        \n",
        "    if not type(orgao) is str:\n",
        "        str(orgao)\n",
        "    orgao = orgao.replace(' ', '_')\n",
        "    nome_df = orgao + '_' + grau + '_' + data + '.csv'\n",
        "    nome_df = nome_df.replace(\" \", \"_\")\n",
        "    if os.path.isdir('./dados'):\n",
        "        os.chdir('dados')\n",
        "    df.to_csv(nome_df, sep=';', header=True, index=False, compression='zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00ad53c2f2db44b199a5d2aa4f488dd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0240d41251db4cd2992f50f16f242f6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90cd0d81914e43ccb1e39af4085f87f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3df1e6b8787447aea4a8e156ef3318ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93191cc9123742d8b1727fbfa609be25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a842ee851d44ce8a034e1cf0878a70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf735a6966f44838904294cd6e6a50ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9849a664b8dd47938126b37541e591e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82e2c2196a5e4c53b64030d864526989",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyError",
          "evalue": "'tribunal'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'tribunal'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset já existente: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m nome_dataset)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mcriar_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43morgao\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m     salvar_dataset(df, \u001b[38;5;28mstr\u001b[39m(orgao), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJE\u001b[39m\u001b[38;5;124m'\u001b[39m, data)\n",
            "Cell \u001b[0;32mIn[5], line 86\u001b[0m, in \u001b[0;36mcriar_dataset\u001b[0;34m(tribunal, data, tamanho_consulta, grau)\u001b[0m\n\u001b[1;32m     84\u001b[0m ultima_posicao_dicionario \u001b[38;5;241m=\u001b[39m dados_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][(\u001b[38;5;28mlen\u001b[39m(dados_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msort\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     85\u001b[0m df_tjrn \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_tjrn, lista_para_dataframe(dados_dict)])\n\u001b[0;32m---> 86\u001b[0m df_tjrn \u001b[38;5;241m=\u001b[39m df_tjrn[\u001b[43mdf_tjrn\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtribunal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m tribunal]\n\u001b[1;32m     87\u001b[0m tamanho_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_tjrn\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     88\u001b[0m ultima_data_ajuizamento \u001b[38;5;241m=\u001b[39m dados_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mlen\u001b[39m(dados_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataAjuizamento\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'tribunal'"
          ]
        }
      ],
      "source": [
        "#lista_orgaos = ['2º JUIZADO ESPECIAL DA FAZENDA PÚBLICA', '3º JUIZADO ESPECIAL DA FAZENDA PÚBLICA', \n",
        "#                '5º JUIZADO ESPECIAL DA FAZENDA PÚBLICA']\n",
        "lista_tribunais = ['TRF1', 'TRF2', 'TRF3', 'TRF4']\n",
        "data = '2018-01-01'\n",
        "for orgao in lista_tribunais:\n",
        "    nome_dataset = nome_df = str(orgao) + '_' + 'JE' + '_' + data + '.csv'\n",
        "    nome_dataset = nome_dataset.replace(\" \", \"_\")\n",
        "    nome_dataset = 'dados/' + nome_dataset\n",
        "    if os.path.isfile(nome_dataset):\n",
        "        print('Dataset já existente: ' + nome_dataset)\n",
        "    else:\n",
        "        df = criar_dataset(orgao, data, 1000)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "        salvar_dataset(df, str(orgao), 'JE', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oikHltKLyjX0",
        "outputId": "3eb7cf67-b513-42ce-be88-783f27008d72"
      },
      "outputs": [],
      "source": [
        "print((df['orgao_julgador'][0]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
